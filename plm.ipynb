{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c48e3d6-9199-47dd-bea8-d9573852ea9a",
   "metadata": {},
   "source": [
    "# Patient Like Me - End to End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b13a79c-583b-4d50-83b4-8ff9fc8b6974",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install \"sagemaker>=2.140.0\" \"transformers==4.26.1\" \"datasets[s3]==2.10.1\" --upgrade\n",
    "# !pip install git+https://github.com/huggingface/transformers.git\n",
    "\n",
    "# !pip install transformers datasets[s3] sagemaker --upgrade\n",
    "# !pip install scikit-learn\n",
    "# !pip install accelerate==0.20.3\n",
    "# !pip install fastprogress\n",
    "# !pip install ollama\n",
    "# !ollama pull llama3\n",
    "# !pip install llama-index==0.10.32\n",
    "# !pip install langchain\n",
    "# !pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27662494-02fd-4813-a8b3-dbce21de310b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO # Python 3.\n",
    "from datasets import load_dataset,Dataset,DatasetDict,concatenate_datasets\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "\n",
    "import pickle\n",
    "from transformers import DataCollatorWithPadding,AutoModelForSequenceClassification, Trainer, TrainingArguments,AutoTokenizer,AutoModel,AutoConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
    "from transformers import TextClassificationPipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pickle\n",
    "from transformers import AdamW, get_scheduler\n",
    "from datasets import load_metric\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c3e3bfe-0218-4dcd-b4e6-fadba9b9def9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival</th>\n",
       "      <th>triage</th>\n",
       "      <th>medrecon</th>\n",
       "      <th>vitals</th>\n",
       "      <th>codes</th>\n",
       "      <th>pyxis</th>\n",
       "      <th>ID</th>\n",
       "      <th>patient_info</th>\n",
       "      <th>eddischarge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33258284</th>\n",
       "      <td>Patient 10000032, a 52 year old white female, ...</td>\n",
       "      <td>At triage: temperature was 98.4, pulse was 70....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2180-...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>The patient did not receive any medications.</td>\n",
       "      <td>10000032</td>\n",
       "      <td>Patient 10000032, a 52 year old white female, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38112554</th>\n",
       "      <td>Patient 10000032, a 52 year old white female, ...</td>\n",
       "      <td>At triage: temperature was 98.9, pulse was 88....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2180-...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>10000032</td>\n",
       "      <td>Patient 10000032, a 52 year old white female, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35968195</th>\n",
       "      <td>Patient 10000032, a 52 year old white female, ...</td>\n",
       "      <td>At triage: temperature was 99.4, pulse was 105...</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2180-...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>10000032</td>\n",
       "      <td>Patient 10000032, a 52 year old white female, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32952584</th>\n",
       "      <td>Patient 10000032, a 52 year old white female, ...</td>\n",
       "      <td>At triage: temperature was 97.8, pulse was 87....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2180-...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>10000032</td>\n",
       "      <td>Patient 10000032, a 52 year old white female, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39399961</th>\n",
       "      <td>Patient 10000032, a 52 year old white female, ...</td>\n",
       "      <td>At triage: temperature was 98.7, pulse was 77....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2180-...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>10000032</td>\n",
       "      <td>Patient 10000032, a 52 year old white female, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34149746</th>\n",
       "      <td>Patient 19999784, a 57 year old black/african ...</td>\n",
       "      <td>At triage: temperature was 98.8, pulse was 92....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2119-...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>19999784</td>\n",
       "      <td>Patient 19999784, a 57 year old black/african ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35692999</th>\n",
       "      <td>Patient 19999784, a 57 year old black/african ...</td>\n",
       "      <td>At triage: temperature was 98.6, pulse was 80....</td>\n",
       "      <td>The patient was previously not taking any medi...</td>\n",
       "      <td>The patient had the following vitals: At 2119-...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>The patient did not receive any medications.</td>\n",
       "      <td>19999784</td>\n",
       "      <td>Patient 19999784, a 57 year old black/african ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32917002</th>\n",
       "      <td>Patient 19999828, a 46 year old white female, ...</td>\n",
       "      <td>At triage: temperature was 96.6, pulse was 112...</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2149-...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>19999828</td>\n",
       "      <td>Patient 19999828, a 46 year old white female, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30712109</th>\n",
       "      <td>Patient 19999828, a 46 year old white female, ...</td>\n",
       "      <td>At triage: temperature was 98.1, pulse was 83....</td>\n",
       "      <td>The patient was previously taking the followin...</td>\n",
       "      <td>The patient had the following vitals: At 2147-...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>19999828</td>\n",
       "      <td>Patient 19999828, a 46 year old white female, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34731548</th>\n",
       "      <td>Patient 19999987, a 57 year old unknown female...</td>\n",
       "      <td>At triage: temperature was not recorded, pulse...</td>\n",
       "      <td>The patient was previously not taking any medi...</td>\n",
       "      <td>The patient had the following vitals: At 2145-...</td>\n",
       "      <td>The patient received the following diagnostic ...</td>\n",
       "      <td>The patient received the following medications...</td>\n",
       "      <td>19999987</td>\n",
       "      <td>Patient 19999987, a 57 year old unknown female...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400019 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    arrival  \\\n",
       "33258284  Patient 10000032, a 52 year old white female, ...   \n",
       "38112554  Patient 10000032, a 52 year old white female, ...   \n",
       "35968195  Patient 10000032, a 52 year old white female, ...   \n",
       "32952584  Patient 10000032, a 52 year old white female, ...   \n",
       "39399961  Patient 10000032, a 52 year old white female, ...   \n",
       "...                                                     ...   \n",
       "34149746  Patient 19999784, a 57 year old black/african ...   \n",
       "35692999  Patient 19999784, a 57 year old black/african ...   \n",
       "32917002  Patient 19999828, a 46 year old white female, ...   \n",
       "30712109  Patient 19999828, a 46 year old white female, ...   \n",
       "34731548  Patient 19999987, a 57 year old unknown female...   \n",
       "\n",
       "                                                     triage  \\\n",
       "33258284  At triage: temperature was 98.4, pulse was 70....   \n",
       "38112554  At triage: temperature was 98.9, pulse was 88....   \n",
       "35968195  At triage: temperature was 99.4, pulse was 105...   \n",
       "32952584  At triage: temperature was 97.8, pulse was 87....   \n",
       "39399961  At triage: temperature was 98.7, pulse was 77....   \n",
       "...                                                     ...   \n",
       "34149746  At triage: temperature was 98.8, pulse was 92....   \n",
       "35692999  At triage: temperature was 98.6, pulse was 80....   \n",
       "32917002  At triage: temperature was 96.6, pulse was 112...   \n",
       "30712109  At triage: temperature was 98.1, pulse was 83....   \n",
       "34731548  At triage: temperature was not recorded, pulse...   \n",
       "\n",
       "                                                   medrecon  \\\n",
       "33258284  The patient was previously taking the followin...   \n",
       "38112554  The patient was previously taking the followin...   \n",
       "35968195  The patient was previously taking the followin...   \n",
       "32952584  The patient was previously taking the followin...   \n",
       "39399961  The patient was previously taking the followin...   \n",
       "...                                                     ...   \n",
       "34149746  The patient was previously taking the followin...   \n",
       "35692999  The patient was previously not taking any medi...   \n",
       "32917002  The patient was previously taking the followin...   \n",
       "30712109  The patient was previously taking the followin...   \n",
       "34731548  The patient was previously not taking any medi...   \n",
       "\n",
       "                                                     vitals  \\\n",
       "33258284  The patient had the following vitals: At 2180-...   \n",
       "38112554  The patient had the following vitals: At 2180-...   \n",
       "35968195  The patient had the following vitals: At 2180-...   \n",
       "32952584  The patient had the following vitals: At 2180-...   \n",
       "39399961  The patient had the following vitals: At 2180-...   \n",
       "...                                                     ...   \n",
       "34149746  The patient had the following vitals: At 2119-...   \n",
       "35692999  The patient had the following vitals: At 2119-...   \n",
       "32917002  The patient had the following vitals: At 2149-...   \n",
       "30712109  The patient had the following vitals: At 2147-...   \n",
       "34731548  The patient had the following vitals: At 2145-...   \n",
       "\n",
       "                                                      codes  \\\n",
       "33258284  The patient received the following diagnostic ...   \n",
       "38112554  The patient received the following diagnostic ...   \n",
       "35968195  The patient received the following diagnostic ...   \n",
       "32952584  The patient received the following diagnostic ...   \n",
       "39399961  The patient received the following diagnostic ...   \n",
       "...                                                     ...   \n",
       "34149746  The patient received the following diagnostic ...   \n",
       "35692999  The patient received the following diagnostic ...   \n",
       "32917002  The patient received the following diagnostic ...   \n",
       "30712109  The patient received the following diagnostic ...   \n",
       "34731548  The patient received the following diagnostic ...   \n",
       "\n",
       "                                                      pyxis         ID  \\\n",
       "33258284       The patient did not receive any medications.  10000032    \n",
       "38112554  The patient received the following medications...  10000032    \n",
       "35968195  The patient received the following medications...  10000032    \n",
       "32952584  The patient received the following medications...  10000032    \n",
       "39399961  The patient received the following medications...  10000032    \n",
       "...                                                     ...        ...   \n",
       "34149746  The patient received the following medications...  19999784    \n",
       "35692999       The patient did not receive any medications.  19999784    \n",
       "32917002  The patient received the following medications...  19999828    \n",
       "30712109  The patient received the following medications...  19999828    \n",
       "34731548  The patient received the following medications...  19999987    \n",
       "\n",
       "                                               patient_info  eddischarge  \n",
       "33258284  Patient 10000032, a 52 year old white female, ...            1  \n",
       "38112554  Patient 10000032, a 52 year old white female, ...            1  \n",
       "35968195  Patient 10000032, a 52 year old white female, ...            1  \n",
       "32952584  Patient 10000032, a 52 year old white female, ...            0  \n",
       "39399961  Patient 10000032, a 52 year old white female, ...            1  \n",
       "...                                                     ...          ...  \n",
       "34149746  Patient 19999784, a 57 year old black/african ...            1  \n",
       "35692999  Patient 19999784, a 57 year old black/african ...            1  \n",
       "32917002  Patient 19999828, a 46 year old white female, ...            1  \n",
       "30712109  Patient 19999828, a 46 year old white female, ...            1  \n",
       "34731548  Patient 19999987, a 57 year old unknown female...            1  \n",
       "\n",
       "[400019 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name = 'chianglab-dataderivatives'\n",
    "file_path = \"mimic-iv-ed-2.2/text_repr.json\"\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "content_object = s3.Object(bucket_name, file_path)\n",
    "file_content = content_object.get()['Body'].read().decode('utf-8')\n",
    "json_content = json.loads(file_content)\n",
    "df = pd.DataFrame(json_content).T\n",
    "\n",
    "df['eddischarge'] = [1 if 'admitted' in s.lower() else 0 for s in df['eddischarge']] # admitted = 1, Home = 0\n",
    "df['medrecon'] = df['medrecon'].fillna(\"The patient was previously not taking any medications.\")\n",
    "df['pyxis'] = df['pyxis'].fillna(\"The patient did not receive any medications.\")\n",
    "df['vitals'] = df['vitals'].fillna(\"The patient had no vitals recorded\")\n",
    "df['codes'] = df['codes'].fillna(\"The patient received no diagnostic codes\")\n",
    "df = df.drop(\"admission\",axis=1)\n",
    "df = df.drop(\"discharge\",axis=1)\n",
    "df = df.drop(\"eddischarge_category\",axis=1)\n",
    "df['ID'] = df.arrival.astype(str).str.split().str[1].replace(\",\", \" \", regex=True).to_list()\n",
    "df[\"patient_info\"] = df[\"arrival\"] + \" \" + df[\"triage\"] + \" \" + df[\"medrecon\"] + \" \" + df[\"vitals\"] + \" \" + df[\"codes\"] + \" \" + df[\"pyxis\"]\n",
    "df = df[[col for col in df.columns if col != 'eddischarge'] + ['eddischarge']] # rearrange column to the end\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25242f13-7e57-4f3b-b1b4-935d237355ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop(\"arrival\",axis=1)\n",
    "df = df.drop(\"triage\",axis=1)\n",
    "df = df.drop(\"medrecon\",axis=1)\n",
    "df = df.drop(\"vitals\",axis=1)\n",
    "df = df.drop(\"codes\",axis=1)\n",
    "df = df.drop(\"pyxis\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23cad1ee-4136-4ae7-bf46-8b79b6b2358b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp = df.sample(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0fd2da-d712-4bc4-bd32-b86d801662e9",
   "metadata": {},
   "source": [
    "# KNN where we bootstrap a group of embeddings and get a more robust prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3cf0ffd-02e4-46ef-98a9-9d9471754ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def knn(query_text, data_source, model_name, n_neighbors=5, n_bootstrap=1000, sample_size=1000):\n",
    "    # Bootstrap a dataframe\n",
    "    df = pd.DataFrame(data_source)\n",
    "    \n",
    "    # Encode the text\n",
    "    def encode_texts(model_name, texts):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModel.from_pretrained(model_name)\n",
    "        model.eval()\n",
    "        if torch.cuda.is_available():\n",
    "            model.to('cuda')\n",
    "        embeddings = []\n",
    "        with torch.no_grad():\n",
    "            for text in tqdm(texts):\n",
    "                encoded_input = tokenizer(text, return_tensors='pt', truncation=True, max_length=512, padding='max_length')\n",
    "                if torch.cuda.is_available():\n",
    "                    encoded_input = {key: val.to('cuda') for key, val in encoded_input.items()}\n",
    "                output = model(**encoded_input)\n",
    "                cls_embedding = output.last_hidden_state[:, 0, :]\n",
    "                embeddings.append(cls_embedding.cpu().numpy())\n",
    "        print(\"embeddings are generated\")\n",
    "        return np.vstack(embeddings)\n",
    "\n",
    "    # Encode all text data\n",
    "    all_embeddings = encode_texts(model_name, df['patient_info'].tolist())\n",
    "    \n",
    "    # Encode the query text\n",
    "    query_embedding = encode_texts(model_name, [query_text])\n",
    "\n",
    "    bootstrap_predictions = []\n",
    "    \n",
    "    for _ in tqdm(range(n_bootstrap), desc=\"Bootstrapping\"):\n",
    "        # Sample indices\n",
    "        sample_indices = np.random.choice(len(df), size=sample_size, replace=True)\n",
    "        \n",
    "        # Get sample data\n",
    "        sample_embeddings = all_embeddings[sample_indices]\n",
    "        sample_df = df.iloc[sample_indices]\n",
    "\n",
    "        # Build KNN embedding space\n",
    "        knn = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine')\n",
    "        knn.fit(sample_embeddings)\n",
    "        \n",
    "        # Query KNN\n",
    "        distances, indices = knn.kneighbors(query_embedding)\n",
    "        \n",
    "        # Get results\n",
    "        results = sample_df.iloc[indices[0]]\n",
    "        \n",
    "        # Make prediction based on majority vote\n",
    "        neighbor_labels = results['eddischarge'].tolist()\n",
    "        prediction = Counter(neighbor_labels).most_common(1)[0][0]\n",
    "        \n",
    "        bootstrap_predictions.append(prediction)\n",
    "\n",
    "    # Final prediction based on majority vote of all bootstrap iterations\n",
    "    final_prediction = Counter(bootstrap_predictions).most_common(1)[0][0]\n",
    "    \n",
    "    # Calculate confidence\n",
    "    confidence = Counter(bootstrap_predictions)[final_prediction] / n_bootstrap\n",
    "\n",
    "    return final_prediction, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ffb260b0-26e0-4c39-a371-356f9235be16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:05<00:00, 79.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings are generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 77.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings are generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrapping: 100%|██████████| 1000/1000 [00:03<00:00, 271.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted eddischarge: 0\n",
      "Ground Truth: 1\n",
      "Confidence: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query_text = df[\"patient_info\"].iloc[0]\n",
    "data_source = temp\n",
    "model_name = \"bert-base-uncased\" \n",
    "prediction, confidence = knn(query_text, data_source, model_name)\n",
    "print(f\"Predicted eddischarge: {prediction}\")\n",
    "print(f\"Ground Truth: {df['eddischarge'].iloc[0]}\")\n",
    "print(f\"Confidence: {confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "97344fd5-43ec-4dbf-b1db-ee50edaff014",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:11<00:00, 140.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings are generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 132.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings are generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrapping: 100%|██████████| 1000/1000 [00:03<00:00, 277.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted eddischarge: 1\n",
      "Ground Truth: 1\n",
      "Confidence: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query_text = df[\"patient_info\"].iloc[0]\n",
    "data_source = temp\n",
    "model_name = \"medicalai/ClinicalBERT\"\n",
    "prediction, confidence = knn(query_text, data_source, model_name)\n",
    "print(f\"Predicted eddischarge: {prediction}\")\n",
    "print(f\"Ground Truth: {df['eddischarge'].iloc[0]}\")\n",
    "print(f\"Confidence: {confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad83c874-a23b-4b04-99c2-51bf09c05a84",
   "metadata": {},
   "source": [
    "# KNN where we return the results table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e333e2a-cc5f-4803-a70b-1e1415c02fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_knn_embeddings(query_text, data_source, model_name, n_neighbors=5):\n",
    "    # Bootstrap a dataframe\n",
    "    df = pd.DataFrame(data_source)\n",
    "\n",
    "    # Encode the text\n",
    "    def encode_texts(model_name, texts):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModel.from_pretrained(model_name)\n",
    "        model.eval()\n",
    "        if torch.cuda.is_available():\n",
    "            model.to('cuda')\n",
    "        embeddings = []\n",
    "        with torch.no_grad():\n",
    "            for text in tqdm(texts):\n",
    "                encoded_input = tokenizer(text, return_tensors='pt', truncation=True, max_length=512, padding='max_length')\n",
    "                if torch.cuda.is_available():\n",
    "                    encoded_input = {key: val.to('cuda') for key, val in encoded_input.items()}\n",
    "                output = model(**encoded_input)\n",
    "                cls_embedding = output.last_hidden_state[:, 0, :]\n",
    "                embeddings.append(cls_embedding.cpu().numpy())\n",
    "        print(\"embeddings are generated\")\n",
    "        return np.vstack(embeddings)\n",
    "    # Assume the text column is named 'patient_info'. Adjust if necessary.\n",
    "    text_embeddings = encode_texts(model_name, df['patient_info'].tolist())\n",
    "\n",
    "    # Build KNN embedding space\n",
    "    knn = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine')\n",
    "    knn.fit(text_embeddings)\n",
    "\n",
    "    # Encode the query text\n",
    "    query_embedding = encode_texts(model_name, [query_text])\n",
    "\n",
    "    # Query KNN\n",
    "    distances, indices = knn.kneighbors(query_embedding)\n",
    "\n",
    "    # Get results\n",
    "    results = df.iloc[indices[0]]\n",
    "    results['distance'] = distances[0]\n",
    "\n",
    "    # Make prediction based on majority vote\n",
    "    neighbor_labels = results['eddischarge'].tolist()\n",
    "    prediction = Counter(neighbor_labels).most_common(1)[0][0]\n",
    "\n",
    "    return results, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7fe59a1d-5dc9-4ccc-8ae6-621b45bfadef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:12<00:00, 80.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings are generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 77.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings are generated\n",
      "                 ID                                       patient_info  \\\n",
      "32394613  18125751   Patient 18125751, a 57 year old white female, ...   \n",
      "34022538  14187451   Patient 14187451, a 53 year old black/african ...   \n",
      "35671330  18242530   Patient 18242530, a 76 year old white female, ...   \n",
      "37661549  14062869   Patient 14062869, a 41 year old white female, ...   \n",
      "32129835  12019283   Patient 12019283, a 25 year old black/african ...   \n",
      "\n",
      "          eddischarge  distance  \n",
      "32394613            0  0.013725  \n",
      "34022538            1  0.016040  \n",
      "35671330            0  0.016175  \n",
      "37661549            0  0.016219  \n",
      "32129835            0  0.017117  \n",
      "-------\n",
      "Predicted eddischarge: 0\n",
      "Ground Truth: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "<ipython-input-38-e356481266bc>:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['distance'] = distances[0]\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "query_text = df[\"patient_info\"].iloc[0]\n",
    "data_source = temp\n",
    "model_name = \"bert-base-uncased\" # or any other model name\n",
    "results, prediction = query_knn_embeddings(query_text, data_source, model_name)\n",
    "print(results)\n",
    "print(\"-------\")\n",
    "print(f\"Predicted eddischarge: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0df0fd5e-e645-4d3f-b6cf-c1acf5a40bb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 141.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings are generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 134.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings are generated\n",
      "                 ID                                       patient_info  \\\n",
      "36599058  16315929   Patient 16315929, a 62 year old white female, ...   \n",
      "32576195  13374041   Patient 13374041, a 58 year old white female, ...   \n",
      "33509281  10018862   Patient 10018862, a 56 year old white female, ...   \n",
      "31725842  18307993   Patient 18307993, a 45 year old black/african ...   \n",
      "32638903  13471464   Patient 13471464, a 73 year old white female, ...   \n",
      "\n",
      "          eddischarge  distance  \n",
      "36599058            1  0.000650  \n",
      "32576195            1  0.000689  \n",
      "33509281            1  0.000711  \n",
      "31725842            1  0.000743  \n",
      "32638903            1  0.000770  \n",
      "-------\n",
      "Predicted eddischarge: 1\n",
      "Ground Truth: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "<ipython-input-38-e356481266bc>:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['distance'] = distances[0]\n"
     ]
    }
   ],
   "source": [
    "query_text = df[\"patient_info\"].iloc[0]\n",
    "data_source = temp\n",
    "model_name = \"medicalai/ClinicalBERT\" \n",
    "results, prediction = query_knn_embeddings(query_text, data_source, model_name)\n",
    "print(results)\n",
    "print(\"-------\")\n",
    "print(f\"Predicted eddischarge: {prediction}\")\n",
    "print(f\"Ground Truth: {df['eddischarge'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da97b300-fe12-405f-b12f-4c453d999ecd",
   "metadata": {},
   "source": [
    "# TODO: We can make plotting features and train test split next\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.g5.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-1.13-gpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
